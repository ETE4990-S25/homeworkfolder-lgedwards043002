{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f26ddd3",
   "metadata": {},
   "source": [
    "\n",
    "# Lab 9: Build a Log Aggregator\n",
    "\n",
    "In this lab, you will create your own log generator, build a command-line utility that scans log files, summarizes their contents, and provides insight into system behavior. Data structures to track log message levels such as `INFO`, `WARNING`, `ERROR`, and `CRITICAL`.\n",
    "\n",
    "This lab reinforces:\n",
    "- File I/O\n",
    "- Pattern recognition (regex)\n",
    "- Dictionaries and counters\n",
    "- Functions and modularity\n",
    "- Optional: CLI arguments, logging\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d5ee8a",
   "metadata": {},
   "source": [
    "\n",
    "## Part 1: Create Log files (20%)\n",
    "Using the the following example log format below create a **python file** that will log errors In a structured tree format \n",
    "\n",
    "You will find examples in the folder called Logs that you can use to build your program.\n",
    "\n",
    "Remember set of logs should have a varied levels of log entries (`INFO`, `WARNING`, `ERROR`, `CRITICAL`) and tailored message types for different service components.\n",
    "You must create 5 structured logs here are some examples:\n",
    "\n",
    "    sqldb\n",
    "    ui\n",
    "    frontend.js\n",
    "    backend.js\n",
    "    frontend.flask\n",
    "    backend.flask\n",
    "\n",
    "You may use chat GPT to create sample outputs NOT THE LOGS. IE:\n",
    "\n",
    "    System failure\n",
    "    Database corruption\n",
    "    Disk failure detected\n",
    "    Database corruption\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec9ba30f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-27 18:41:03,311, frontend.js, WARNING, User attempted invalid operation\n",
      "2025-04-27 18:41:03,313, backend.flask, ERROR, Failed to fetch user data\n",
      "2025-04-27 18:41:03,316, backend.js, CRITICAL, System failure detected\n"
     ]
    }
   ],
   "source": [
    "# Paste your python file here \n",
    "# don't forget to upload it with your submission\n",
    "import logging\n",
    "from logging.handlers import RotatingFileHandler\n",
    "\n",
    "#custom logger\n",
    "logger = logging.getLogger(__name__)\n",
    "sqldb_logger = logging.getLogger(\"sqldb\")\n",
    "frontend_logger = logging.getLogger(\"frontend.js\")\n",
    "backend_flask_logger = logging.getLogger(\"backend.flask\")\n",
    "backend_logger = logging.getLogger(\"backend.js\")\n",
    "frontend_flask_logger = logging.getLogger(\"frontend.flask\")\n",
    "\n",
    "\n",
    "#handler which controls where the log messages go\n",
    "console_handler = logging.StreamHandler()\n",
    "#file_handler = logging.FileHandler()\n",
    "rotating_file_handler = RotatingFileHandler(\"app.log\", maxBytes=2000)\n",
    "\n",
    "console_handler.setLevel(logging.WARNING)\n",
    "rotating_file_handler.setLevel(logging.ERROR)\n",
    "\n",
    "logging_format = logging.Formatter(\"%(asctime)s, %(name)s, %(levelname)s, %(message)s\")\n",
    "\n",
    "console_handler.setFormatter(logging_format)\n",
    "rotating_file_handler.setFormatter(logging_format)\n",
    "\n",
    "for log in [sqldb_logger, frontend_logger, backend_flask_logger, backend_logger, frontend_flask_logger]:\n",
    "    log.setLevel(logging.DEBUG)\n",
    "    log.addHandler(console_handler)\n",
    "    log.addHandler(rotating_file_handler)\n",
    "\n",
    "# logger.warning(\"This is a warning\")\n",
    "# logger.error(\"This is a error\")\n",
    "\n",
    "sqldb_logger.info(\"Database connection successful\")\n",
    "frontend_logger.warning(\"User attempted invalid operation\")\n",
    "backend_flask_logger.error(\"Failed to fetch user data\")\n",
    "backend_logger.critical(\"System failure detected\")\n",
    "frontend_flask_logger.info(\"Homepage loaded successfully\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5255ab",
   "metadata": {},
   "source": [
    "\n",
    "### Example Log Format\n",
    "\n",
    "You will work with logs that follow this simplified structure:\n",
    "\n",
    "```\n",
    "2025-04-11 23:20:36,913 | my_app | INFO | Request completed\n",
    "2025-04-11 23:20:36,914 | my_app.utils | ERROR | Unhandled exception\n",
    "2025-04-11 23:20:36,914 | my_app.utils.db | CRITICAL | Disk failure detected\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3659dfbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af5f6e84",
   "metadata": {},
   "source": [
    "## Part 2: Logging the Log File (40%)\n",
    "    New File\n",
    "### Part 2a: Read the Log File (see lab 7) (10%)\n",
    "\n",
    "\n",
    "Write a function to read the contents of a log file into a list of lines. Handle file errors gracefully.\n",
    "\n",
    "### Part 2b: Parse Log Lines (see code below if you get stuck) (10%)\n",
    "\n",
    "Use a regular expression to extract:\n",
    "- Timestamp\n",
    "- Log name\n",
    "- Log level\n",
    "- Message\n",
    "\n",
    "### Part 2c: Count Log Levels (20%)\n",
    "\n",
    "Create a function to count how many times each log level appears. Store the results in a dictionary. Then output it as a Json File\n",
    "You may pick your own format but here is an example. \n",
    "```python\n",
    "{\n",
    "    \"INFO\": \n",
    "    {\n",
    "        \"Request completed\": 42, \n",
    "        \"Heartbeat OK\": 7\n",
    "    }\n",
    "\n",
    "    \"WARNING\":\n",
    "    {\n",
    "        ...\n",
    "    }\n",
    "}\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bc631f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', '== Chocolate Doom installation ==\\n', '\\n', 'These are instructions for how to install and set up Chocolate Doom\\n', 'for play.\\n', '\\n', '== Obtaining an IWAD file ==\\n', '\\n', 'To play, you need an IWAD file.  This file contains the game data\\n', '(graphics, sounds, etc). The full versions of the games are\\n', 'proprietary and need to be bought.  The IWAD file has one of the\\n', 'following names:\\n', '\\n', '   doom1.wad                   (Shareware Doom)\\n', '   doom.wad                    (Registered / Ultimate Doom)\\n', '   doom2.wad                   (Doom 2)\\n', '   tnt.wad                     (Final Doom: TNT: Evilution)\\n', '   plutonia.wad                (Final Doom: Plutonia Experiment)\\n', '   chex.wad                    (Chex Quest)\\n', '   freedm.wad                  (FreeDM)\\n', '\\n', \"If you don't have a copy of a commercial version, you can download\\n\", 'the shareware version of Doom (extract the file named doom1.wad):\\n', '\\n', ' * https://www.doomworld.com/idgames/idstuff/doom/win95/doom95\\n', '   (idstuff/doom/win95/doom95.zip in your nearest /idgames mirror)\\n', '\\n', 'If you have a commercial version on a CD-ROM, obtaining the IWAD\\n', 'file is usually straightforward. Simply locate the IWAD file on the\\n', 'disc and copy it off.\\n', '\\n', 'The Doom games, along with Heretic and Hexen, are also available to\\n', 'purchase for download on Steam (http://www.steampowered.com/).\\n', 'Chocolate Doom will autodetect IWADs installed by Steam and you do\\n', 'not need to do anything.\\n', '\\n', 'Older floppy disk versions are harder to deal with. The easiest way\\n', 'to install from floppies is to run the original installer program\\n', 'inside an emulator such as DOSbox (http://www.dosbox.com/).\\n', 'As an alternative to using an emulator, it is possible to extract the\\n', 'files manually. On the install disk(s), you will find several files\\n', 'with numbered extensions (eg. \"doom_se.1\").\\n', '\\n', 'From the command line it is possible to combine these files into a\\n', 'single large file, using a command similar to the following:\\n', '\\n', '   copy doom_se.1+doom_se.2+doom_se.3+doom_se.4+doom_se.5 doom_se.lzh\\n', '\\n', 'The resulting file is an LHA archive file, and it can be extracted\\n', 'using an LHA archive tool (there is one available for almost every\\n', 'operating system).\\n', '\\n', '== Running the game ==\\n', '\\n', 'Chocolate Doom needs to know where to find your IWAD file. To do this,\\n', 'do one of the following:\\n', '\\n', ' * Within Explorer, simply place the IWAD file in the same folder as\\n', '   the Chocolate Doom files, and double-click chocolate-doom.exe.\\n', '\\n', \" * Run Chocolate Doom from the command prompt with the '-iwad' command\\n\", '   line parameter to specify the IWAD file to use, eg.\\n', '\\n', '       chocolate-doom -iwad c:\\\\games\\\\doom2.wad\\n', '\\n', ' * Set the environment variable DOOMWADDIR to the location of a\\n', '   directory containing your IWAD files.\\n', '\\n', ' * If you have multiple IWADs in different directories, set the\\n', '   environment variable DOOMWADPATH to be a semicolon-separated list\\n', '   of directories to search (similar to the PATH environment\\n', '   variable).\\n', '\\n', '== Playing with Freedoom ==\\n', '\\n', 'Freedoom is an open content project to create a Doom engine-based game\\n', 'that is entirely free software. The website can be found here:\\n', '\\n', '  https://freedoom.github.io/\\n', '\\n', 'The main Freedoom IWAD files are not currently compatible with\\n', 'Chocolate Doom. However, you can play using FreeDM, the\\n', 'deathmatch spinoff project. If you want to play single player games,\\n', \"you'll need to download additional fan-made WAD files to use in\\n\", \"conjunction with it. Check out the Chocolate Doom wiki's page on\\n\", 'Freedoom for some suggestions.\\n', '\\n', '== Playing with Chex Quest ==\\n', '\\n', 'Chex Quest is a game based on Doom with some minor modifications that\\n', 'was distributed with boxes of Chex cereal in 1997.  It is possible to\\n', 'play Chex Quest using Chocolate Doom.  To do this, the following files\\n', 'are needed:\\n', '\\n', \" * The IWAD file 'chex.wad', from the Chex Quest CD.\\n\", '\\n', \" * The dehacked patch 'chex.deh', which can be found here:\\n\", '   https://www.doomworld.com/idgames/utils/exe_edit/patches/chexdeh\\n', '   (utils/exe_edit/patches/chexdeh.zip in your nearest /idgames mirror)\\n', '\\n', \"Copy these files into a directory together and use the '-iwad' command\\n\", 'line parameter to specify the Chex Quest IWAD file:\\n', '\\n', '   chocolate-doom -iwad chex.wad\\n', '\\n', '== Installing upgrades ==\\n', '\\n', 'Chocolate Doom requires a version 1.9 IWAD file.  Generally, if you\\n', 'install a recent version of Doom you should have a version 1.9 IWAD.\\n', 'However, if you are installing from a very old CD version or from\\n', 'floppy disks, you might find you have an older version.\\n', '\\n', 'The most obvious symptom of an out of date IWAD file is that the game\\n', 'will exit at the title screen before the demo starts, with the message\\n', '\"Demo is from a different game version!\".  If this happens, your IWAD\\n', 'file is out of date and you need to upgrade.\\n', '\\n', 'Upgrade patches are available that will update your game to the latest\\n', 'version, the following sites have the patches:\\n', '\\n', '  http://www.doom2.net/doom2/utils.html\\n', '  ftp://ftp.idsoftware.com/idstuff/doom\\n', '  ftp://ftp.idsoftware.com/idstuff/doom2\\n', '\\n', 'Please see http://doomwiki.org/wiki/Game_patch for more information.\\n', '\\n', 'As the patches are binary patches that run as DOS executables, on\\n', 'recent 64-bit versions of Windows you will need to use a DOS emulator\\n', '(such as DOSBox) to run them.\\n', '\\n', '== Music support ==\\n', '\\n', 'Chocolate Doom includes OPL emulation code that accurately reproduces\\n', 'the way that the in-game music sounded under DOS when using an\\n', \"Adlib/Soundblaster card. This is, however, not to everyone's taste.\\n\", '\\n', 'Chocolate Doom includes a number of different options for better\\n', 'quality MIDI playback; see the file README.Music for more details of\\n', 'how to set these up.\\n', '\\n', '# vim: tw=70\\n', '\\n']\n"
     ]
    }
   ],
   "source": [
    "# Part 2a\n",
    "def read_log_file(file_path):\n",
    "    try:\n",
    "        with open(file_path, \"r\") as file:\n",
    "            lines = file.readlines()\n",
    "        return lines\n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: Log file not found.\")\n",
    "        return []\n",
    "    \n",
    "#You can replace the app.log with a file you want. I added the r in front of my file path so it would read my file path as normal characters and not special commands.\n",
    "lines = read_log_file(r\"C:\\Users\\loren\\OneDrive\\Desktop\\DOOM\\chocolate-doom-3.0.1-win32 (1)\\INSTALL.txt\")\n",
    "print(lines)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5f8a0b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"{'timestamp': ' 2025-04-27T12:10:00Z'\", \"'level': 'ERROR'\", \"'component': 'backend.flask'\", \"'message': 'Failed to fetch user data'}\")\n",
      "(\"{'timestamp': ' 2025-04-27T12:15:00Z'\", \"'level': 'CRITICAL'\", \"'component': 'backend.js'\", \"'message': 'System failure detected'}\")\n",
      "('2025-04-27 11:31:32,664', 'backend.flask', 'ERROR', 'Failed to fetch user data')\n",
      "('2025-04-27 11:31:32,665', 'backend.js', 'CRITICAL', 'System failure detected')\n",
      "('2025-04-27 11:33:14,483', 'backend.flask', 'ERROR', 'Failed to fetch user data')\n",
      "('2025-04-27 11:33:14,483', 'backend.flask', 'ERROR', 'Failed to fetch user data')\n",
      "('2025-04-27 11:33:14,487', 'backend.js', 'CRITICAL', 'System failure detected')\n",
      "('2025-04-27 11:33:14,487', 'backend.js', 'CRITICAL', 'System failure detected')\n",
      "('2025-04-27 11:34:21,729', 'backend.flask', 'ERROR', 'Failed to fetch user data')\n",
      "('2025-04-27 11:34:21,729', 'backend.flask', 'ERROR', 'Failed to fetch user data')\n",
      "('2025-04-27 11:34:21,729', 'backend.flask', 'ERROR', 'Failed to fetch user data')\n",
      "('2025-04-27 11:34:21,732', 'backend.js', 'CRITICAL', 'System failure detected')\n",
      "('2025-04-27 11:34:21,732', 'backend.js', 'CRITICAL', 'System failure detected')\n",
      "('2025-04-27 11:34:21,732', 'backend.js', 'CRITICAL', 'System failure detected')\n",
      "('2025-04-27 18:34:42,102', 'backend.flask', 'ERROR', 'Failed to fetch user data')\n",
      "('2025-04-27 18:34:42,117', 'backend.js', 'CRITICAL', 'System failure detected')\n",
      "('2025-04-27 18:35:10,462', 'backend.flask', 'ERROR', 'Failed to fetch user data')\n",
      "('2025-04-27 18:35:10,465', 'backend.js', 'CRITICAL', 'System failure detected')\n",
      "('2025-04-27 18:36:28,304', 'backend.flask', 'ERROR', 'Failed to fetch user data')\n",
      "('2025-04-27 18:36:28,306', 'backend.js', 'CRITICAL', 'System failure detected')\n",
      "('2025-04-27 18:41:03,313', 'backend.flask', 'ERROR', 'Failed to fetch user data')\n",
      "('2025-04-27 18:41:03,316', 'backend.js', 'CRITICAL', 'System failure detected')\n"
     ]
    }
   ],
   "source": [
    "#Part 2b\n",
    "import re\n",
    "\n",
    "def split_log_line(line):\n",
    "    pattern = r\"(.+?), (.+?), (.+?), (.+)\"\n",
    "    match = re.match(pattern, line)\n",
    "    if match:\n",
    "        timestamp, component, level, message = match.groups()\n",
    "        return timestamp, component, level, message\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "lines = read_log_file(\"app.log\")\n",
    "for line in lines:\n",
    "    result = split_log_line(line)\n",
    "    if result:\n",
    "        print(result)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fdcbeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def count_log_levels(lines):\n",
    "    log_counts = {}\n",
    "\n",
    "    for line in lines:\n",
    "        result = split_log_line(line)\n",
    "        if result:\n",
    "            timestamp, component, level, message, = result\n",
    "\n",
    "            if level not in log_counts:\n",
    "                log_counts[level] = {}\n",
    "\n",
    "            if message not in log_counts[level]:\n",
    "                log_counts[level] = {}\n",
    "\n",
    "            if message not in log_counts[level]:\n",
    "                log_counts[level][message] = 1\n",
    "            else:\n",
    "                log_counts[level][message] += 1\n",
    "            \n",
    "    return log_counts\n",
    "lines = read_log_file(\"app.log\")\n",
    "counts = count_log_levels(lines)\n",
    "        \n",
    "with open(\"log_summary.json\", \"w\") as json_file:\n",
    "    json.dump(counts, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4045c30f",
   "metadata": {},
   "source": [
    "\n",
    "## Step 3: Generate Summary Report (40%)\n",
    "    New File\n",
    "### Step 3a (20%):\n",
    " Develop a function that continuously monitors your JSON file(s) and will print a real-time summary of log activity. It should keep count of the messages grouped by log level (INFO, WARNING, ERROR, CRITICAL) and display only the critical messages. (I.e. If new data comes in the summary will change and a new critical message will be printed)\n",
    " - note: do not reprocess the entire file on each update.  \n",
    "\n",
    "### Step 3b: Use a Matplotlib (Lecture 10) (20%)\n",
    "Develop a function that continuously monitors your JSON file(s) and will graph in real-time a bar or pie plot of each of the errors.  (a graph for each log level). \n",
    "- The graph should show the distribution of log messages by level  (INFO, WARNING, ERROR, CRITICAL)  \n",
    "\n",
    "\n",
    "### Critical notes:\n",
    "- Your code mus use Daemon Threads (Lecture 14)\n",
    "- 3a and 3b do not need to run at the same time. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea4429f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import threading\n",
    "import time\n",
    "\n",
    "def monitor_log_summary():\n",
    "    try:\n",
    "        with open(\"log_summary.json\", \"r\") as file:\n",
    "            old_data = json.load(file)\n",
    "    except FileNotFoundError:\n",
    "        old_data = {}\n",
    "\n",
    "    while True:\n",
    "\n",
    "        try:\n",
    "            with open(\"log_summary.json\", \"r\") as file:\n",
    "                new_data = json.load(file)\n",
    "        except FileNotFoundError:\n",
    "            new_data = {}\n",
    "            \n",
    "        if new_data != old_data:\n",
    "            print(\"\\n--- Updated Log Summary ---\")\n",
    "            for level in new_data:\n",
    "                total = sum(new_data[level].values())\n",
    "                print(f\"{level}: {total}\")\n",
    "                \n",
    "            if \"CRITICAL\" in new_data:\n",
    "                for message in new_data[\"CRITICAL\"]:\n",
    "                    if \"CRITICAL\" not in old_data or message not in old_data[\"CRITICAL\"]:\n",
    "                        print(f\"CRITICAL Message: {message}\")\n",
    "\n",
    "            old_data = new_data\n",
    "            \n",
    "        time.sleep(2)\n",
    "\n",
    "monitor_thread = threading.Thread(target=monitor_log_summary, daemon=True)\n",
    "monitor_thread.start()\n",
    "\n",
    "while True:\n",
    "    time.sleep(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26eb058",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "import threading\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_log_summary():\n",
    "    try:\n",
    "        with open(\"log_summary.json\", \"r\") as file:\n",
    "            old_data = json.load(file)\n",
    "    except FileNotFoundError:\n",
    "        old_data = {}\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            with open(\"log_summary.json\", \"r\") as file:\n",
    "                new_data = json.load(file)\n",
    "        except FileNotFoundError:\n",
    "            new_data = {}\n",
    "\n",
    "        if new_data != old_data:\n",
    "            plt.clf()\n",
    "            fig, axs = plt.subplots(2, 2, figsize=(10, 8))\n",
    "            fig.suptitle(\"Log Summary by Level\")\n",
    "\n",
    "            levels = [\"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\"]\n",
    "            positions = [(0,0), (0,1), (1,0), (1,1)]\n",
    "\n",
    "            for level, pos in zip(levels, positions):\n",
    "                row, col = pos\n",
    "                ax = axs[row][col]\n",
    "\n",
    "                if level in new_data:\n",
    "                    messages = list(new_data[level].keys())\n",
    "                    counts = list(new_data[level].values())\n",
    "                    ax.bar(messages, counts)\n",
    "                    ax.set_title(level)\n",
    "                    ax.set_ylabel(\"Count\")\n",
    "                    ax.set_xticklabels(messages, rotation=45, ha=\"right\")\n",
    "                else:\n",
    "                    ax.set_title(level)\n",
    "                    ax.set_xticks([])\n",
    "                    ax.set_yticks([])\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.pause(0.1)\n",
    "            old_data = new_data\n",
    "\n",
    "        time.sleep(2)\n",
    "\n",
    "monitor_thread = threading.Thread(target=plot_log_summary, daemon=True)\n",
    "monitor_thread.start()\n",
    "\n",
    "while True:\n",
    "    time.sleep(1)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
